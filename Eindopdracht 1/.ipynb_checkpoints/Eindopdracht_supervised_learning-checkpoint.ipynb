{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voorspellen van politieke partij op basis van tekst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.snowball import DutchStemmer\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inlezen SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>agenda_item</th>\n",
       "      <th>turn_no</th>\n",
       "      <th>speaker</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Detijdelijke voorzitter:Ik deel aan de Kamer m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Voorzitter. Ik zal het idee van de heer Pechto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Zo mogelijk in aanwezigheid van de minister-pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Ik kan mij die behoefte heel goed voorstellen....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Steun namens D66 voor het verzoek van de heer ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  agenda_item  turn_no  speaker  \\\n",
       "0   1            1        1        1   \n",
       "1   2            5        1        2   \n",
       "2   3            5        2        2   \n",
       "3   4            5        3        3   \n",
       "4   5            5        4        4   \n",
       "\n",
       "                                                 txt  \n",
       "0  Detijdelijke voorzitter:Ik deel aan de Kamer m...  \n",
       "1  Voorzitter. Ik zal het idee van de heer Pechto...  \n",
       "2  Zo mogelijk in aanwezigheid van de minister-pr...  \n",
       "3  Ik kan mij die behoefte heel goed voorstellen....  \n",
       "4  Steun namens D66 voor het verzoek van de heer ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = sqlite3.connect('reports.sqlite')\n",
    "\n",
    "agenda_items = pd.read_sql_query(\"SELECT * FROM agenda_items\", db)\n",
    "speaker_items = pd.read_sql_query(\"SELECT * FROM speaker_turns\", db)\n",
    "speakers = pd.read_sql_query(\"SELECT * FROM speakers\", db)\n",
    "\n",
    "# controle of het inlezen goed gaat\n",
    "agenda_items.head()\n",
    "speaker_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Politieke partijen toevoegen aan personen wanneer deze bekend was\n",
    "De personen die niet tot een politieke partij behoren zijn niet benoemd tot een politieke partij en deze zullen in de volgende stap (bij het mergen) vanzelf uit de dataset gehaald worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers.loc[speakers['id'] == 48,'political'] = 'VVD' # minister Rutte behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 49,'political'] = 'CDA'# meneer van Dam behoort tot het CDA\n",
    "speakers.loc[speakers['id'] == 51,'political'] = 'VVD' # minister Hennis-Plasschaert behoort bij de VVD\n",
    "speakers.loc[speakers['id'] == 54,'political'] = 'PvdA' # staatssecretaris Dijksma behoort tot PvdA\n",
    "speakers.loc[speakers['id'] == 56,'political'] = 'VVD' # staatssecretaris Wiebes behoort tot VVD\n",
    "speakers.loc[speakers['id'] == 84,'political'] = 'VVD' # mevrouw Schippers behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 94,'political'] = 'PvdA'# Staatssecretaris van Rijn behoort tot de PvdA\n",
    "speakers.loc[speakers['id'] == 98,'political'] = 'PvdA'# minister Plasterk behoort tot de PvdA\n",
    "speakers.loc[speakers['id'] == 106,'political'] = 'VVD' # minister Blok behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 108,'political'] = 'PvdA' # minister Koenders behoort tot de PvdA\n",
    "speakers.loc[speakers['id'] == 115,'political'] = 'PvdA' # minister Ploumen behoort tot de PvdA\n",
    "speakers.loc[speakers['id'] == 118,'political'] = 'VVD' # minister Schultz van Haegen-Maas Geesteranus behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 125,'political'] = 'PvdA' # minister Asscher behoort tot de PvdA\n",
    "speakers.loc[speakers['id'] == 134,'political'] = 'PvdA' # straatssecretaris Kleijnsma behoort tot de PvdA\n",
    "speakers.loc[speakers['id'] == 136,'political'] = 'PvdA' # minister Ploumen behoort tot de PvdA\n",
    "speakers.loc[speakers['id'] == 140,'political'] = 'PvdA' # minister Dijsselbloem behoort tot de PvdA\n",
    "speakers.loc[speakers['id'] == 141,'political'] = 'VVD' # staatssecretaris Dijkhoff behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 148,'political'] = 'VVD' # minister Kamp behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 149,'political'] = 'VVD' # staatssecretaris Dekker behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 157,'political'] = 'PvdA' # minister Bussemaker behoort tot de PvdA\n",
    "speakers.loc[speakers['id'] == 169,'political'] = 'SP' # mevrouw Leijten behoort tot de SP\n",
    "speakers.loc[speakers['id'] == 180,'political'] = 'CU' # mevrouw Schouten behoort tot de CU\n",
    "speakers.loc[speakers['id'] == 181,'political'] = 'VVD' # minister Bruins behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 182,'political'] = 'CDA' # minister De Jonge behoort tot de CDA\n",
    "speakers.loc[speakers['id'] == 183,'political'] = 'CDA' # minister Grapperhaus behoort tot de CDA\n",
    "speakers.loc[speakers['id'] == 184,'political'] = 'D66' # minister Koolmees behoort tot de D66\n",
    "speakers.loc[speakers['id'] == 185,'political'] = 'CDA' # minister Bijleveld behoort tot de CDA\n",
    "speakers.loc[speakers['id'] == 186,'political'] = 'VVD' # minister Dekker behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 189,'political'] = 'D66' # minister Kaag behoort tot de D66\n",
    "speakers.loc[speakers['id'] == 190,'political'] = 'VVD' # minister Knops behoort tot de CDA\n",
    "speakers.loc[speakers['id'] == 191,'political'] = 'VVD' # minister Zijlstra behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 192,'political'] = 'CDA' # minister Hoekstra behoort tot de CDA\n",
    "speakers.loc[speakers['id'] == 193,'political'] = 'D66' # Staatssecretaris Snel behoort tot de D66\n",
    "speakers.loc[speakers['id'] == 194,'political'] = 'CU' # minister Slob behoort tot de CU\n",
    "speakers.loc[speakers['id'] == 195,'political'] = 'VVD' # minister Wiebes behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 197,'political'] = 'CDA' # staatssecretaris Keijzer behoort tot de CDA\n",
    "speakers.loc[speakers['id'] == 198,'political'] = 'D66' # minister Ollogren behoort tot de D66\n",
    "speakers.loc[speakers['id'] == 203,'political'] = 'VVD' # Staatssecretaris Visser behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 204,'political'] = 'VVD' # Staatssecretaris Van Ark behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 207,'political'] = 'D66' # Minister Van Engelshoven behoort tot de D66\n",
    "speakers.loc[speakers['id'] == 210,'political'] = 'VVD' # Minister Van Nieuwenhuizen-Wijbenga behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 211,'political'] = 'D66' # Staatssecretaris Van Veldhoven behoort tot de D66\n",
    "speakers.loc[speakers['id'] == 212,'political'] = 'VVD' # Staatssecretaris Harbers behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 213,'political'] = 'CU' # Staatssecretaris Blokhuis behoort tot de CU\n",
    "speakers.loc[speakers['id'] == 217,'political'] = 'PvdD' # De heer Wassenberg behoort tot de PvdD\n",
    "speakers.loc[speakers['id'] == 218,'political'] = 'VVD' # De heer Van Meenen behoort tot de D66\n",
    "speakers.loc[speakers['id'] == 233,'political'] = 'CDA' # Minister Bijleveld-Schouten behoort tot de CDA\n",
    "speakers.loc[speakers['id'] == 234,'political'] = 'D66' # Staatssecretaris Van Veldhoven-van der Meer behoort tot de D66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prefix</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50PLUS</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDA</th>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CU</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChristenUnie</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D66</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DENK</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/CDA</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/CU/SGP</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/D66</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/GroenLinks</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/PvdA</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/PvdD</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/SP</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/VVD</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forum voor Democratie</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FvD</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GroenLinks</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PVV</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PvdA</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PvdD</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGP</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VVD</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  prefix  name\n",
       "political                              \n",
       "50PLUS                  5       5     5\n",
       "CDA                    29      28    29\n",
       "CU                      3       3     3\n",
       "ChristenUnie            6       6     6\n",
       "D66                    30      30    30\n",
       "DENK                    3       3     3\n",
       "EP/CDA                  1       1     1\n",
       "EP/CU/SGP               1       1     1\n",
       "EP/D66                  1       1     1\n",
       "EP/GroenLinks           1       1     1\n",
       "EP/PvdA                 1       1     1\n",
       "EP/PvdD                 1       1     1\n",
       "EP/SP                   1       1     1\n",
       "EP/VVD                  1       1     1\n",
       "Forum voor Democratie   2       2     2\n",
       "FvD                     2       2     2\n",
       "GroenLinks             17      17    17\n",
       "PVV                    21      21    21\n",
       "PvdA                   21      21    21\n",
       "PvdD                    9       9     9\n",
       "SGP                     4       4     4\n",
       "SP                     17      17    17\n",
       "VVD                    59      59    59"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# controle van het aantal sprekers per politieke partij\n",
    "speakers.groupby('political').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder hebben we de sprekerdataset en wat ze gezegd hebben samengevoegd. Alle tekst van personen die Iedereen die niet tot een politieke partij behoord is uit de datset gehaald. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = speaker_items.merge(speakers, left_on='speaker', right_on='id')[['txt','political']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50PLUS</th>\n",
       "      <td>3477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDA</th>\n",
       "      <td>14344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CU</th>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChristenUnie</th>\n",
       "      <td>3568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D66</th>\n",
       "      <td>14947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DENK</th>\n",
       "      <td>3773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/CDA</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/CU/SGP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/D66</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/GroenLinks</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/PvdA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/PvdD</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/SP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/VVD</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forum voor Democratie</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FvD</th>\n",
       "      <td>2029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GroenLinks</th>\n",
       "      <td>10093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PVV</th>\n",
       "      <td>8442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PvdA</th>\n",
       "      <td>8535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PvdD</th>\n",
       "      <td>4050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGP</th>\n",
       "      <td>2720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP</th>\n",
       "      <td>12083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VVD</th>\n",
       "      <td>20777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         txt\n",
       "political                   \n",
       "50PLUS                  3477\n",
       "CDA                    14344\n",
       "CU                      1863\n",
       "ChristenUnie            3568\n",
       "D66                    14947\n",
       "DENK                    3773\n",
       "EP/CDA                     3\n",
       "EP/CU/SGP                  1\n",
       "EP/D66                     1\n",
       "EP/GroenLinks              1\n",
       "EP/PvdA                    1\n",
       "EP/PvdD                    1\n",
       "EP/SP                      1\n",
       "EP/VVD                     7\n",
       "Forum voor Democratie     66\n",
       "FvD                     2029\n",
       "GroenLinks             10093\n",
       "PVV                     8442\n",
       "PvdA                    8535\n",
       "PvdD                    4050\n",
       "SGP                     2720\n",
       "SP                     12083\n",
       "VVD                    20777"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# controle welke partijen er zijn met hoeveel tekst\n",
    "merged.groupby('political').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uit bovenstaande lijst blijkt dat er door mensen van het europees parlement maar weinig wordt gezegd. Omdat hier zo weinig tekst van beschikbaar is, willen we deze niet meenemen in ons model, en hebben we alle teksten Europese parlementariers uit de dataset verwijderd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              txt\n",
      "political        \n",
      "50PLUS       3477\n",
      "CDA         14344\n",
      "CU           5431\n",
      "D66         14947\n",
      "DENK         3773\n",
      "FvD          2095\n",
      "GroenLinks  10093\n",
      "PVV          8442\n",
      "PvdA         8535\n",
      "PvdD         4050\n",
      "SGP          2720\n",
      "SP          12083\n",
      "VVD         20777\n"
     ]
    }
   ],
   "source": [
    "merged = merged[~merged['political'].isin(['EP/CDA', 'EP/CU/SGP', 'EP/D66', \n",
    "                                           'EP/GroenLinks', 'EP/PvdA', 'EP/PvdD',\n",
    "                                           'EP/SP', 'EP/VVD'])]\n",
    "merged = merged.dropna()\n",
    "merged = merged.replace('Forum voor Democratie','FvD')\n",
    "merged = merged.replace('ChristenUnie','CU')\n",
    "print(merged.groupby('political').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in train en test set\n",
    "X = merged['txt']\n",
    "Y = merged.political.astype('category').values.codes\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We willen ook onderzoeken een stemmer toevoegen, op die manier worden vervoegingen van woorden als hetzelfde woord meegeteld en we verwachten dat dit ons model beter zal laten presteren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemmer\n",
    "stemmer = DutchStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder hebben we een pijplijn gebouwd om te classificeren. \n",
    "Aan deze pijplijn hebben we toegevoegd:\n",
    "- een countvectorizer die telt hoe vaak woorden voorkomen in een tekst. Hieraan hebben we een stemmer toegevoegd die ervoor zorgd dat vervoegingen van woorden als één woord worden meegeteld. Verder hebben we opgegeven of er gegeken moet worden per woord, of dat ook combinaties van woorden bekeken moeten worden. We hebben getest welk aantal woorden het best werkt en hieruit bleek dat het geen toegevoegde waarde heeft om voor meerdere woorden te kijken, dus ngram_range = (1,1). Verder wilden we ook de stopwoorden verwijderen. Omdat we in eerste instantie niet een goede Nederlandse stopwoordenlijst konden vinden, hebben we ervoor gekozen om gebruik te maken van de max_df parameter die volgens de documentatie tussen de 0,7 en 1 gezet kon worden om automatisch stopwoorden te detecteren. \n",
    "- We hebben een TfidfTransformer toegevoegd om de juiste woorden belangrijker te maken.\n",
    "- Daarna hebben we een model toegevoegd. Hieronder hebben we voor verschillende modellen getest waar de hoogste accuracy is behaald."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20542565676627245\n",
      "177.76475930213928\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "# accuracy score: 0.20542565676627245"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corien\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4075110589509795\n",
      "188.7903389930725\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "# Accuracy score: 0.4075110589509795"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corien\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\corien\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4043062200956938\n",
      "243.44670152664185\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "# Accuracy score 0.4043062200956938"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SVC())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "# duurt te lang om te runnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corien\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3936535162950257\n",
      "192.40455865859985\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', PassiveAggressiveClassifier())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "#Accuracy score: 0.3936535162950257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13099214588787578\n",
      "412.84075927734375\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', KNeighborsClassifier())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "#Accuracy score: 0.13099214588787578"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.252098943757335\n",
      "302.8725302219391\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', AdaBoostClassifier())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "# Accuracy score: 0.252098943757335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23431434503927057\n",
      "726.0362014770508\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', DecisionTreeClassifier())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "# Accuracy score: 0.23431434503927057"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corien\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22808522163040534\n",
      "516.2958481311798\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RandomForestClassifier())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "# Accuracy score: 0.22808522163040534"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het best scorende model is de SDG classifier en logistic regression. We zullen nu (een deel) van de parameters proberen te optimaliseren, om het uiteindelijke model te bepalen. We hebben nu ook een andere manier gevonden om stopwoorden te verwijderen, namelijk met een lijst. We zullen eerst de parameters optimaliseren met een stopwoordenlijst en daarna nog een keer een optimalisatie maar dan door max_df op verschillende waarden te zetten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "stopwoorden = get_stop_words('dutch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corien\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 hinge l2 0.3165116908910355\n",
      "0.7 hinge l1 0.31718876952243386\n",
      "0.7 hinge elasticnet 0.30816105443712194\n",
      "0.7 log l2 0.31330685203574976\n",
      "0.7 log l1 0.31962625259546806\n",
      "0.7 log elasticnet 0.31867834251151034\n",
      "0.85 hinge l2 0.3156089193825043\n",
      "0.85 hinge l1 0.31457073214769343\n",
      "0.85 hinge elasticnet 0.3214317956125305\n",
      "0.85 log l2 0.31754987812584634\n",
      "0.85 log l1 0.3184526496343775\n",
      "0.85 log elasticnet 0.317279046673287\n",
      "1 hinge l2 0.3230567843278866\n",
      "1 hinge l1 0.3141644849688544\n",
      "1 hinge elasticnet 0.3170984923715808\n",
      "1 log l2 0.3201679155005868\n",
      "1 log l1 0.3181818181818182\n",
      "1 log elasticnet 0.31497697932653246\n"
     ]
    }
   ],
   "source": [
    "# bepalen parameters SDG classifier met stopwoorden verwijderen door hoeveel ze voorkomen in het document\n",
    "max_df_param = 0.7\n",
    "loss_param = \"log\"\n",
    "penalty_param = \"l2\"\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = max_df_param)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss=loss_param, penalty = penalty_param))])\n",
    "\n",
    "for max_df_param in [0.7,0.85,1]:\n",
    "    for loss_param in [\"hinge\",\"log\"]:\n",
    "        for penalty_param in [\"l2\",\"l1\",\"elasticnet\"]:\n",
    "            pipeline.fit(X_train,Y_train)\n",
    "            predicted = pipeline.predict(X_test)\n",
    "            print(max_df_param, loss_param, penalty_param, accuracy_score(predicted,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hinge l2 0.3197165297463212\n",
      "1 hinge l1 0.31606030513676986\n",
      "1 hinge elasticnet 0.3175047395504198\n",
      "1 log l2 0.3148867021756793\n",
      "1 log l1 0.31813667960639164\n",
      "1 log elasticnet 0.315022117901959\n"
     ]
    }
   ],
   "source": [
    "# bepalen parameters SDG classifier met stopwoordenlijst\n",
    "loss_param = \"log\"\n",
    "penalty_param = \"l2\"\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), stop_words = stopwoorden)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss=loss_param, penalty = penalty_param))])\n",
    "\n",
    "for loss_param in [\"hinge\",\"log\"]:\n",
    "    for penalty_param in [\"l2\",\"l1\",\"elasticnet\"]:\n",
    "        pipeline.fit(X_train,Y_train)\n",
    "        predicted = pipeline.predict(X_test)\n",
    "        print(max_df_param, loss_param, penalty_param, accuracy_score(predicted,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het blijkt dat de aangepaste versies van de modellen niet zo goed werken. De accuracy scores liggen namelijk net iets boven de 30%, terwijl het oorspronkelijke model rond de 40% zat. Waarschijnlijk heb ik dus niet de juiste parameters verandert. Daarom blijft het beste model alsnog het SDG model waarbij verder geen parameters zijn gespecificeerd. Hieronder is het beste model weergegeven. Het bleek dat de max_df aangeven bij dit model beter werkte dan de stopwoordenlijst, dus daarom is in het beste model de max_df gebruikt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4098582648731606\n",
      "176.0409574508667\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "# Accuracy score: 0.4098582648731606"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
