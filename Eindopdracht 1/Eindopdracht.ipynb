{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voorspellen van politieke partij op basis van tekst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.snowball import DutchStemmer\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inlezen SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>agenda_item</th>\n",
       "      <th>turn_no</th>\n",
       "      <th>speaker</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Detijdelijke voorzitter:Ik deel aan de Kamer m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Voorzitter. Ik zal het idee van de heer Pechto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Zo mogelijk in aanwezigheid van de minister-pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Ik kan mij die behoefte heel goed voorstellen....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Steun namens D66 voor het verzoek van de heer ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  agenda_item  turn_no  speaker  \\\n",
       "0   1            1        1        1   \n",
       "1   2            5        1        2   \n",
       "2   3            5        2        2   \n",
       "3   4            5        3        3   \n",
       "4   5            5        4        4   \n",
       "\n",
       "                                                 txt  \n",
       "0  Detijdelijke voorzitter:Ik deel aan de Kamer m...  \n",
       "1  Voorzitter. Ik zal het idee van de heer Pechto...  \n",
       "2  Zo mogelijk in aanwezigheid van de minister-pr...  \n",
       "3  Ik kan mij die behoefte heel goed voorstellen....  \n",
       "4  Steun namens D66 voor het verzoek van de heer ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = sqlite3.connect('reports.sqlite')\n",
    "\n",
    "agenda_items = pd.read_sql_query(\"SELECT * FROM agenda_items\", db)\n",
    "speaker_items = pd.read_sql_query(\"SELECT * FROM speaker_turns\", db)\n",
    "speakers = pd.read_sql_query(\"SELECT * FROM speakers\", db)\n",
    "\n",
    "# controle of het inlezen goed gaat\n",
    "agenda_items.head()\n",
    "speaker_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Politieke partijen toevoegen aan personen wanneer deze bekend was\n",
    "De personen die niet tot een politieke partij behoren zijn niet benoemd tot een politieke partij en deze zullen in de volgende stap (bij het mergen) vanzelf uit de dataset gehaald worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers.loc[speakers['id'] == 48,'political'] = 'VVD' # minister Rutte behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 49,'political'] = 'CDA'# meneer van Dam behoort tot het CDA\n",
    "speakers.loc[speakers['id'] == 51,'political'] = 'VVD' # minister Hennis-Plasschaert behoort bij de VVD\n",
    "speakers.loc[speakers['id'] == 54,'political'] = 'PvdA' # staatssecretaris Dijksma behoort tot PvdA\n",
    "speakers.loc[speakers['id'] == 56,'political'] = 'VVD' # staatssecretaris Wiebes behoort tot VVD\n",
    "speakers.loc[speakers['id'] == 84,'political'] = 'VVD' # mevrouw Schippers behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 94,'political'] = 'PvdA'# Staatssecretaris van Rijn behoort tot de PvdA\n",
    "speakers.loc[speakers['id'] == 98,'political'] = 'PvdA'# minister Plasterk behoort tot de PvdA\n",
    "speakers.loc[speakers['id'] == 106,'political'] = 'VVD' # minister Blok behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 108,'political'] = 'PvdA' # minister Koenders behoort tot de PvdA\n",
    "speakers.loc[speakers['id'] == 115,'political'] = 'PvdA' # minister Ploumen behoort tot de PvdA\n",
    "speakers.loc[speakers['id'] == 118,'political'] = 'VVD' # minister Schultz van Haegen-Maas Geesteranus behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 125,'political'] = 'PvdA' # minister Asscher behoort tot de PvdA\n",
    "speakers.loc[speakers['id'] == 134,'political'] = 'PvdA' # straatssecretaris Kleijnsma behoort tot de PvdA\n",
    "speakers.loc[speakers['id'] == 136,'political'] = 'PvdA' # minister Ploumen behoort tot de PvdA\n",
    "speakers.loc[speakers['id'] == 140,'political'] = 'PvdA' # minister Dijsselbloem behoort tot de PvdA\n",
    "speakers.loc[speakers['id'] == 141,'political'] = 'VVD' # staatssecretaris Dijkhoff behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 148,'political'] = 'VVD' # minister Kamp behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 149,'political'] = 'VVD' # staatssecretaris Dekker behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 157,'political'] = 'PvdA' # minister Bussemaker behoort tot de PvdA\n",
    "speakers.loc[speakers['id'] == 169,'political'] = 'SP' # mevrouw Leijten behoort tot de SP\n",
    "speakers.loc[speakers['id'] == 180,'political'] = 'CU' # mevrouw Schouten behoort tot de CU\n",
    "speakers.loc[speakers['id'] == 181,'political'] = 'VVD' # minister Bruins behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 182,'political'] = 'CDA' # minister De Jonge behoort tot de CDA\n",
    "speakers.loc[speakers['id'] == 183,'political'] = 'CDA' # minister Grapperhaus behoort tot de CDA\n",
    "speakers.loc[speakers['id'] == 184,'political'] = 'D66' # minister Koolmees behoort tot de D66\n",
    "speakers.loc[speakers['id'] == 185,'political'] = 'CDA' # minister Bijleveld behoort tot de CDA\n",
    "speakers.loc[speakers['id'] == 186,'political'] = 'VVD' # minister Dekker behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 189,'political'] = 'D66' # minister Kaag behoort tot de D66\n",
    "speakers.loc[speakers['id'] == 190,'political'] = 'VVD' # minister Knops behoort tot de CDA\n",
    "speakers.loc[speakers['id'] == 191,'political'] = 'VVD' # minister Zijlstra behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 192,'political'] = 'CDA' # minister Hoekstra behoort tot de CDA\n",
    "speakers.loc[speakers['id'] == 193,'political'] = 'D66' # Staatssecretaris Snel behoort tot de D66\n",
    "speakers.loc[speakers['id'] == 194,'political'] = 'CU' # minister Slob behoort tot de CU\n",
    "speakers.loc[speakers['id'] == 195,'political'] = 'VVD' # minister Wiebes behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 197,'political'] = 'CDA' # staatssecretaris Keijzer behoort tot de CDA\n",
    "speakers.loc[speakers['id'] == 198,'political'] = 'D66' # minister Ollogren behoort tot de D66\n",
    "speakers.loc[speakers['id'] == 203,'political'] = 'VVD' # Staatssecretaris Visser behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 204,'political'] = 'VVD' # Staatssecretaris Van Ark behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 207,'political'] = 'D66' # Minister Van Engelshoven behoort tot de D66\n",
    "speakers.loc[speakers['id'] == 210,'political'] = 'VVD' # Minister Van Nieuwenhuizen-Wijbenga behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 211,'political'] = 'D66' # Staatssecretaris Van Veldhoven behoort tot de D66\n",
    "speakers.loc[speakers['id'] == 212,'political'] = 'VVD' # Staatssecretaris Harbers behoort tot de VVD\n",
    "speakers.loc[speakers['id'] == 213,'political'] = 'CU' # Staatssecretaris Blokhuis behoort tot de CU\n",
    "speakers.loc[speakers['id'] == 217,'political'] = 'PvdD' # De heer Wassenberg behoort tot de PvdD\n",
    "speakers.loc[speakers['id'] == 218,'political'] = 'VVD' # De heer Van Meenen behoort tot de D66\n",
    "speakers.loc[speakers['id'] == 233,'political'] = 'CDA' # Minister Bijleveld-Schouten behoort tot de CDA\n",
    "speakers.loc[speakers['id'] == 234,'political'] = 'D66' # Staatssecretaris Van Veldhoven-van der Meer behoort tot de D66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prefix</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50PLUS</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDA</th>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CU</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChristenUnie</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D66</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DENK</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/CDA</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/CU/SGP</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/D66</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/GroenLinks</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/PvdA</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/PvdD</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/SP</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/VVD</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forum voor Democratie</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FvD</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GroenLinks</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PVV</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PvdA</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PvdD</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGP</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VVD</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  prefix  name\n",
       "political                              \n",
       "50PLUS                  5       5     5\n",
       "CDA                    29      28    29\n",
       "CU                      3       3     3\n",
       "ChristenUnie            6       6     6\n",
       "D66                    30      30    30\n",
       "DENK                    3       3     3\n",
       "EP/CDA                  1       1     1\n",
       "EP/CU/SGP               1       1     1\n",
       "EP/D66                  1       1     1\n",
       "EP/GroenLinks           1       1     1\n",
       "EP/PvdA                 1       1     1\n",
       "EP/PvdD                 1       1     1\n",
       "EP/SP                   1       1     1\n",
       "EP/VVD                  1       1     1\n",
       "Forum voor Democratie   2       2     2\n",
       "FvD                     2       2     2\n",
       "GroenLinks             17      17    17\n",
       "PVV                    21      21    21\n",
       "PvdA                   21      21    21\n",
       "PvdD                    9       9     9\n",
       "SGP                     4       4     4\n",
       "SP                     17      17    17\n",
       "VVD                    59      59    59"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# controle van het aantal sprekers per politieke partij\n",
    "speakers.groupby('political').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder hebben we de sprekerdataset en wat ze gezegd hebben samengevoegd. Alle tekst van personen die Iedereen die niet tot een politieke partij behoord is uit de datset gehaald. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = speaker_items.merge(speakers, left_on='speaker', right_on='id')[['txt','political']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50PLUS</th>\n",
       "      <td>3477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDA</th>\n",
       "      <td>14344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CU</th>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChristenUnie</th>\n",
       "      <td>3568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D66</th>\n",
       "      <td>14947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DENK</th>\n",
       "      <td>3773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/CDA</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/CU/SGP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/D66</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/GroenLinks</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/PvdA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/PvdD</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/SP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP/VVD</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forum voor Democratie</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FvD</th>\n",
       "      <td>2029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GroenLinks</th>\n",
       "      <td>10093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PVV</th>\n",
       "      <td>8442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PvdA</th>\n",
       "      <td>8535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PvdD</th>\n",
       "      <td>4050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGP</th>\n",
       "      <td>2720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP</th>\n",
       "      <td>12083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VVD</th>\n",
       "      <td>20777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         txt\n",
       "political                   \n",
       "50PLUS                  3477\n",
       "CDA                    14344\n",
       "CU                      1863\n",
       "ChristenUnie            3568\n",
       "D66                    14947\n",
       "DENK                    3773\n",
       "EP/CDA                     3\n",
       "EP/CU/SGP                  1\n",
       "EP/D66                     1\n",
       "EP/GroenLinks              1\n",
       "EP/PvdA                    1\n",
       "EP/PvdD                    1\n",
       "EP/SP                      1\n",
       "EP/VVD                     7\n",
       "Forum voor Democratie     66\n",
       "FvD                     2029\n",
       "GroenLinks             10093\n",
       "PVV                     8442\n",
       "PvdA                    8535\n",
       "PvdD                    4050\n",
       "SGP                     2720\n",
       "SP                     12083\n",
       "VVD                    20777"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# controle welke partijen er zijn met hoeveel tekst\n",
    "merged.groupby('political').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uit bovenstaande lijst blijkt dat er door mensen van het europees parlement maar weinig wordt gezegd. Omdat hier zo weinig tekst van beschikbaar is, willen we deze niet meenemen in ons model, en hebben we alle teksten Europese parlementariers uit de dataset verwijderd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              txt\n",
      "political        \n",
      "50PLUS       3477\n",
      "CDA         14344\n",
      "CU           5431\n",
      "D66         14947\n",
      "DENK         3773\n",
      "FvD          2095\n",
      "GroenLinks  10093\n",
      "PVV          8442\n",
      "PvdA         8535\n",
      "PvdD         4050\n",
      "SGP          2720\n",
      "SP          12083\n",
      "VVD         20777\n"
     ]
    }
   ],
   "source": [
    "merged = merged[~merged['political'].isin(['EP/CDA', 'EP/CU/SGP', 'EP/D66', \n",
    "                                           'EP/GroenLinks', 'EP/PvdA', 'EP/PvdD',\n",
    "                                           'EP/SP', 'EP/VVD'])]\n",
    "merged = merged.dropna()\n",
    "merged = merged.replace('Forum voor Democratie','FvD')\n",
    "merged = merged.replace('ChristenUnie','CU')\n",
    "print(merged.groupby('political').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in train en test set\n",
    "X = merged['txt']\n",
    "Y = merged.political.astype('category').values.codes\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We willen ook onderzoeken of het helpt om een stemmer toe te voegen, op die manier worden vervoegingen van woorden als hetzelfde woord megeteld en we verwachten dat dit ons model beter zal laten presteren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemmer\n",
    "stemmer = DutchStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder hebben we een pijnlijn gebouwd om te classificeren. \n",
    "Aan deze pijplijn hebben we toegevoegd:\n",
    "- een countvectorizer die telt hoe vaak woorden voorkomen in een tekst. Hieraan hebben we een stemmer toegevoegd die ervoor zorgd dat .... Om de stopwoorden te verwijderen konden "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-dc15796800d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    229\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1032\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-97ba821679e4>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstemmed_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/stem/snowball.py\u001b[0m in \u001b[0;36mstem\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m   1142\u001b[0m                 \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m         \u001b[0mr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_r1r2_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__vowels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;31m# R1 is adjusted so that the region before it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/stem/snowball.py\u001b[0m in \u001b[0;36m_r1r2_standard\u001b[0;34m(self, word, vowels)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvowels\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvowels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                 \u001b[0mr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "# accuracy score: 0.20542565676627245"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "# Accuracy score: 0.4075110589509795"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "# Accuracy score 0.4043062200956938"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SVC())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "# duurt te lang om te runnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corien\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3936535162950257\n",
      "192.40455865859985\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', PassiveAggressiveClassifier())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "#Accuracy score: 0.3936535162950257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13099214588787578\n",
      "412.84075927734375\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', KNeighborsClassifier())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "#Accuracy score: 0.13099214588787578"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.252098943757335\n",
      "302.8725302219391\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', AdaBoostClassifier())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "# Accuracy score: 0.252098943757335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23431434503927057\n",
      "726.0362014770508\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', DecisionTreeClassifier())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "# Accuracy score: 0.23431434503927057"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corien\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22808522163040534\n",
      "516.2958481311798\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RandomForestClassifier())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "# Accuracy score: 0.22808522163040534"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het best scorende model is de SDG classifier. We zullen nu (een deel) van de parameters proberen te optimaliseren, om het uiteindelijke model te bepalen. We hebben nu ook een andere manier gevonden om stopwoorden te verwijderen, namelijk met een lijst. We zullen eerst de parameters optimaliseren met een stopwoordenlijst en daarna nog een keer een optimalisatie maar dan door max_df op verschillende waarden te zetten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "stopwoorden = get_stop_words('dutch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4071048117721405\n",
      "235.85338354110718\n"
     ]
    }
   ],
   "source": [
    "# optimaliseren van de SGD Classifier met stopwoordenlijst\n",
    "for data_verwijderen in [1,2,3]:\n",
    "    print data_verwijderen\n",
    "\n",
    "\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svc = svm.SVC(gamma=\"scale\")\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(iris.data, iris.target)\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)\n",
    "\n",
    "# nu met stop woorden\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), stop_words = stopwoorden)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier())])\n",
    "     \n",
    "t = time.time()\n",
    "pipeline.fit(X_train,Y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(accuracy_score(predicted,Y_test))\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_verwijderen in [1,2,3]:\n",
    "    print data_verwijderen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voor als we dit nog nodig hebben\n",
    "N = np.min(merged.groupby('political').size())\n",
    "\n",
    "sample50PLUS = merged[merged['political'] == '50PLUS'].sample(n = N, random_state = 1)\n",
    "sampleCDA = merged[merged['political'] == 'CDA'].sample(n = N, random_state = 1)\n",
    "sampleCU = merged[merged['political'] == 'CU'].sample(n = N, random_state = 1)\n",
    "sampleD66 = merged[merged['political'] == 'D66'].sample(n = N, random_state = 1)\n",
    "sampleDENK = merged[merged['political'] == 'DENK'].sample(n = N, random_state = 1)\n",
    "sampleFvD = merged[merged['political'] == 'FvD'].sample(n = N, random_state = 1)\n",
    "sampleGL = merged[merged['political'] == 'GroenLinks'].sample(n = N, random_state = 1)\n",
    "samplePVV = merged[merged['political'] == 'PVV'].sample(n = N, random_state = 1)\n",
    "samplePvdA = merged[merged['political'] == 'PvdA'].sample(n = N, random_state = 1)\n",
    "samplePvdD = merged[merged['political'] == 'PvdD'].sample(n = N, random_state = 1)\n",
    "sampleSGP = merged[merged['political'] == 'SGP'].sample(n = N, random_state = 1)\n",
    "sampleSP = merged[merged['political'] == 'SP'].sample(n = N, random_state = 1)\n",
    "sampleVVD = merged[merged['political'] == 'VVD'].sample(n = N, random_state = 1)\n",
    "\n",
    "data = pd.concat([sample50PLUS,sampleCDA,sampleCU,sampleD66,sampleDENK,sampleFvD,\n",
    "                  sampleGL,samplePVV,samplePvdA,samplePvdD,sampleSGP,sampleSP,sampleVVD])\n",
    "\n",
    "print(data.groupby('political').count())\n",
    "data['political'] = data.political.astype('category').values.codes\n",
    "\n",
    "\n",
    "# eventueel de nederlandse woordenlijst\n",
    "# stopwoordenlijst inlezen\n",
    "text_file = open(\"stopwoordenlijst.txt\", \"r\")\n",
    "stopwoorden = text_file.readlines()\n",
    "stopwoorden = [line[:-1] for line in stopwoorden]\n",
    "stopwoorden[0] = 'a'\n",
    "print(stopwoorden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aan',\n",
       " 'al',\n",
       " 'alles',\n",
       " 'als',\n",
       " 'altijd',\n",
       " 'andere',\n",
       " 'ben',\n",
       " 'bij',\n",
       " 'daar',\n",
       " 'dan',\n",
       " 'dat',\n",
       " 'de',\n",
       " 'der',\n",
       " 'deze',\n",
       " 'die',\n",
       " 'dit',\n",
       " 'doch',\n",
       " 'doen',\n",
       " 'door',\n",
       " 'dus',\n",
       " 'een',\n",
       " 'eens',\n",
       " 'en',\n",
       " 'er',\n",
       " 'ge',\n",
       " 'geen',\n",
       " 'geweest',\n",
       " 'haar',\n",
       " 'had',\n",
       " 'heb',\n",
       " 'hebben',\n",
       " 'heeft',\n",
       " 'hem',\n",
       " 'het',\n",
       " 'hier',\n",
       " 'hij',\n",
       " 'hoe',\n",
       " 'hun',\n",
       " 'iemand',\n",
       " 'iets',\n",
       " 'ik',\n",
       " 'in',\n",
       " 'is',\n",
       " 'ja',\n",
       " 'je',\n",
       " 'kan',\n",
       " 'kon',\n",
       " 'kunnen',\n",
       " 'maar',\n",
       " 'me',\n",
       " 'meer',\n",
       " 'men',\n",
       " 'met',\n",
       " 'mij',\n",
       " 'mijn',\n",
       " 'moet',\n",
       " 'na',\n",
       " 'naar',\n",
       " 'niet',\n",
       " 'niets',\n",
       " 'nog',\n",
       " 'nu',\n",
       " 'of',\n",
       " 'om',\n",
       " 'omdat',\n",
       " 'onder',\n",
       " 'ons',\n",
       " 'ook',\n",
       " 'op',\n",
       " 'over',\n",
       " 'reeds',\n",
       " 'te',\n",
       " 'tegen',\n",
       " 'toch',\n",
       " 'toen',\n",
       " 'tot',\n",
       " 'u',\n",
       " 'uit',\n",
       " 'uw',\n",
       " 'van',\n",
       " 'veel',\n",
       " 'voor',\n",
       " 'want',\n",
       " 'waren',\n",
       " 'was',\n",
       " 'wat',\n",
       " 'werd',\n",
       " 'wezen',\n",
       " 'wie',\n",
       " 'wil',\n",
       " 'worden',\n",
       " 'wordt',\n",
       " 'zal',\n",
       " 'ze',\n",
       " 'zelf',\n",
       " 'zich',\n",
       " 'zij',\n",
       " 'zijn',\n",
       " 'zo',\n",
       " 'zonder',\n",
       " 'zou']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stopwoorden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = stemmed_words, ngram_range=(1,1), max_df = 0.7)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', KMeans(n_clusters = 13, random_state=0, max_iter = 10))])\n",
    "     \n",
    "t = time.time()\n",
    "merged['k_means_cluster'] = pipeline.fit_predict(X)\n",
    "merged.head()\n",
    "print(time.time() - t)\n",
    "\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
